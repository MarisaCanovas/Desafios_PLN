# ğŸ“š DesafÃ­o 3 â€” LSTM para generaciÃ³n de texto

Entrega correspondiente al DesafÃ­o 3 del curso de PLN. Este proyecto implementa un modelo LSTM para generaciÃ³n carÃ¡cter por carÃ¡cter, con control de temperatura y visualizaciÃ³n de mÃ©tricas.

## ğŸ“¦ Contenido del archivo `Entrega_LSTM_Marisa_Canovas.zip`

- `DesafÃ­o 3 LSTM CÃ¡novas.ipynb` â€” Notebook con todo el desarrollo, entrenamiento, visualizaciÃ³n y generaciÃ³n.
- `best_model_lstm.keras` â€” Modelo entrenado guardado en la Ã©poca con menor perplejidad.
- `history_ppl.npy` â€” Historial de perplejidad por Ã©poca.
- `loss_history.npy` â€” Historial de pÃ©rdida por Ã©poca.
- `best_epoch.npy` â€” Ãndice de la mejor Ã©poca (mÃ­nima PPL).
- `best_ppl.npy` â€” Valor mÃ­nimo de perplejidad alcanzado.
- `grafico_loss_y_perplejidad_lstm.png` â€” VisualizaciÃ³n de mÃ©tricas de entrenamiento y validaciÃ³n.

## ğŸ§  Notas tÃ©cnicas

- Se utilizÃ³ `temperature` para controlar la creatividad en la generaciÃ³n.
- El modelo se entrenÃ³ con callbacks personalizados para calcular PPL.
- Se implementÃ³ guardado automÃ¡tico del mejor modelo y sus mÃ©tricas.
- El grÃ¡fico final muestra la evoluciÃ³n de `loss` y `PPL`, marcando la mejor Ã©poca.
